{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 InputLayer False\n",
      "1 Conv2D False\n",
      "2 Conv2D False\n",
      "3 MaxPooling2D False\n",
      "4 Conv2D False\n",
      "5 Conv2D False\n",
      "6 MaxPooling2D False\n",
      "7 Conv2D False\n",
      "8 Conv2D False\n",
      "9 Conv2D False\n",
      "10 MaxPooling2D False\n",
      "11 Conv2D False\n",
      "12 Conv2D False\n",
      "13 Conv2D False\n",
      "14 MaxPooling2D False\n",
      "15 Conv2D False\n",
      "16 Conv2D False\n",
      "17 Conv2D False\n",
      "18 MaxPooling2D False\n",
      "Model: \"model_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_16 (InputLayer)        (None, 244, 244, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 244, 244, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 244, 244, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 122, 122, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 122, 122, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 122, 122, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 61, 61, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 61, 61, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 61, 61, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 61, 61, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 30, 30, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 30, 30, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 30, 30, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 30, 30, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 15, 15, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 15, 15, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 15, 15, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 15, 15, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 256)               6422784   \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 4)                 1028      \n",
      "=================================================================\n",
      "Total params: 21,138,500\n",
      "Trainable params: 6,423,812\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n",
      "None\n",
      "Found 64 images belonging to 4 classes.\n",
      "Found 16 images belonging to 4 classes.\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 96s 1s/step - loss: 1.9286 - accuracy: 0.8342 - val_loss: 5.9605e-07 - val_accuracy: 0.8125\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.00000, saving model to actor.h5\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 97s 2s/step - loss: 0.4762 - accuracy: 0.9027 - val_loss: 2.6822e-07 - val_accuracy: 0.8125\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.00000 to 0.00000, saving model to actor.h5\n"
     ]
    }
   ],
   "source": [
    "from keras.applications import VGG16\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "#Loads the VGG16 model \n",
    "model = VGG16(weights = 'imagenet', include_top = False, input_shape = (244, 244, 3))\n",
    "\n",
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "# Let's print our layers \n",
    "for (i,layer) in enumerate(model.layers):\n",
    "    print(str(i) + \" \"+ layer.__class__.__name__, layer.trainable)\n",
    "    \n",
    "def Top(bottom_model, num_classes, D=256):\n",
    "    head = bottom_model.output\n",
    "    head = Flatten(name = \"flatten\")(head)\n",
    "    head = Dense(D, activation = \"relu\")(head)\n",
    "    head = Dropout(0.3)(head)\n",
    "    head = Dense(num_classes, activation = \"softmax\")(head)\n",
    "    return head\n",
    "\n",
    "top = addTopModel(model, 4)\n",
    "modelnew = Model(inputs=model.input, outputs=top)\n",
    "\n",
    "print(modelnew.summary())\n",
    "\n",
    "training = 'G:/MLOPS/transfer_learninig_vgg16/images/train'\n",
    "testing = 'G:/MLOPS/transfer_learninig_vgg16/images/test'\n",
    "\n",
    "train_data = ImageDataGenerator( rescale=1./255, rotation_range=20, width_shift_range=0.2, height_shift_range=0.2,\n",
    "horizontal_flip=True, fill_mode='nearest')\n",
    " \n",
    "test_data = ImageDataGenerator(rescale=1./255)\n",
    "train_batchsize = 6\n",
    "val_batchsize = 4\n",
    " \n",
    "train_gen = train_datagen.flow_from_directory(training, target_size=(244, 244), batch_size=train_batchsize,\n",
    "                                              class_mode='categorical')\n",
    " \n",
    "test_gen = validation_datagen.flow_from_directory(testing, target_size=(244,244), batch_size=val_batchsize,\n",
    "class_mode='categorical', shuffle=False)                   \n",
    "checkpoint = ModelCheckpoint(\"actor.h5\", monitor=\"val_loss\", mode=\"min\", save_best_only = True,\n",
    "                             verbose=1)\n",
    "earlystop = EarlyStopping(monitor = 'val_loss', min_delta = 0, patience = 3, verbose = 1, restore_best_weights = True)\n",
    "callbacks = [earlystop, checkpoint]\n",
    "\n",
    "modelnew.compile(loss = 'categorical_crossentropy', optimizer = RMSprop(lr = 0.001),\n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "train_img = 64\n",
    "test_img = 16\n",
    "epochs = 2\n",
    "batch_size = 1\n",
    "\n",
    "history = modelnew.fit_generator( train_gen, steps_per_epoch = train_img // batch_size, epochs = epochs,\n",
    "callbacks = callbacks, validation_data = test_gen, validation_steps = test_img // batch_size)\n",
    "\n",
    "modelnew.save(\"actor.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
